{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#x1f12f; Javier Bejar - APA/GEI/FIB/UPC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to upgrade packages\n",
    "# !pip install pandas --user --upgrade --quiet\n",
    "# !pip install numpy --user --upgrade --quiet\n",
    "# !pip install scipy --user --upgrade --quiet\n",
    "# !pip install seaborn --user --upgrade --quiet\n",
    "# !pip install matplotlib --user --upgrade --quiet\n",
    "# !pip install scikit-learn --upgrade --user --quiet\n",
    "!pip install scikit-optimize --user --quiet\n",
    "!pip install apafib --upgrade --user --quiet\n",
    "!pip install wordcloud --upgrade --user --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from IPython.display import display, HTML\n",
    "show_html = lambda html: display(HTML(html))\n",
    "\n",
    "from time import time\n",
    "from datetime import timedelta\n",
    "\n",
    "init_time = time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APA - Laboratorio - Sesión 6\n",
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from sklearn import set_config\n",
    "\n",
    "from sklearn.metrics import  ConfusionMatrixDisplay,\\\n",
    "                    classification_report,  RocCurveDisplay, PrecisionRecallDisplay,\\\n",
    "                    accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, make_scorer, mean_absolute_error\n",
    "from yellowbrick.classifier.rocauc import roc_auc\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split, cross_val_score, TimeSeriesSplit\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from apafib import load_arxiv, load_energy\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "np.int = int # fix for skopt\n",
    "\n",
    "import warnings\n",
    "\n",
    "set_config(display='text')\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "pd.set_option('display.precision', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(clf, X_test, y_test, nclf, df):\n",
    "    df.loc[nclf,'train XV acc'] = clf.best_score_\n",
    "    df.loc[nclf,'test acc'] = accuracy_score(y_test, clf.predict(X_test))\n",
    "    df.loc[nclf,'precision score (W)'] = precision_score(y_test, clf.predict(X_test), average='weighted')\n",
    "    df.loc[nclf,'recall score (W)'] = recall_score(y_test, clf.predict(X_test), average='weighted')\n",
    "    df.loc[nclf,'f1 score (W)'] = f1_score(y_test, clf.predict(X_test), average='weighted')\n",
    "    return df\n",
    "\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "niter = 15\n",
    "cv = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sección 1: Arxiv abstracts (Clasificación)\n",
    "\n",
    "No todos los conjuntos de datos que se usan para generar modelos corresponden a datos tabulares, en algunos problemas debemos transformar datos no estructurados de alguna manera para poder usarlos.\n",
    "\n",
    "Este es el caso del texto. Antes de que se pueda usar debemos realizar un preproceso que nos de una matriz de datos sobre la que podamos aplicar un modelo.\n",
    "\n",
    "En este caso particular el proceso habitual sigue los siguientes pasos (los que hayáis o estéis haciendo CAIM ya los conocéreis)\n",
    "\n",
    "1. Tokenización: Dividir el texto en palabras (usando espacios en blanco o expresiones regulares)\n",
    "2. Normalización: Transformar los token a un formato único para que la misma palabra (minúsculas, eliminación de acentos, caracteres no ASCII...)\n",
    "3. Eliminación de stop words: Quitar palabras que no tienen significiado por si mismas (preposiciones, adverbios, artículos). Claramente depende del idioma\n",
    "4. Lematización: Transformación de las palabras a su raíz. Esto también depende del idioma\n",
    "5. Reducción del vocabulario a un rango de frecuencias (ni las más frecuentes, ni las muy poco frecuentes)\n",
    "6. Transformación de cada texto a un vector de características: \n",
    "   - Binario (la palabra esta o no)\n",
    "   - Conteo (Cuantas veces aparece la palabra)  \n",
    "   - Importancia de la palabra respecto al conjunto de documentos, por ejemplo TFIDF\n",
    "        TF = term frequency, cuantas veces aparece la palabra en el documento\n",
    "        IDF = inverse document frequency, en cuantos documentos aparece la palabra\n",
    "\n",
    "Esta representación del texto se conoce como **Bag of words**, representa cada documento por una lista de palabras perteneciente a un vocabulario y un atributo calculado para cada uno de ellos.\n",
    "\n",
    "Una vez tenemos los datos como una matriz podemos aplicar cualquier modelo.\n",
    "\n",
    "En este caso trabajaremos con un conjunto de datos que corresponde a resúmenes de artículos científicos extraidos de Arxiv (https://arxiv.org/). Podemos obtener los textos mediante la función de _apafib_ `load_arxiv`. Esto nos retornara dos listas, una con las etiquetas de los documentos y otra con los documentos.\n",
    "\n",
    "En este conjunto de datos tenemos articulos de cuatro categorías: astro-ph, cs, math, physics. Hay 1000 ejemplos de cada categoría.\n",
    "\n",
    "Comenzaremos cargando los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, labels = load_arxiv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos 4000 ejemplos en total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text), len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es el primer ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text[0], labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de procesar el texto lo dividiremos en conjunto de entrenamiento y test, también transformaremos la etiquetas textuales a números"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(text, labels, test_size=0.3, random_state=42, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenc = LabelEncoder()\n",
    "y_train_l = lenc.fit_transform(y_train)\n",
    "y_test_l = lenc.transform(y_test)\n",
    "cls = lenc.inverse_transform(np.unique(y_train_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformación a matriz de datos\n",
    "\n",
    "Consideraremos diferentes formas de transformar el texto a una matriz de datos, para este fin scikit-learn tiene dos funciones especiales para ello:\n",
    "\n",
    "-  `CountVectorizer` que permite obtener el conteo de palabras, pero también la representación binaria\n",
    "-  `TfidfVectorizer` que calcula el TFIDF de las palabras\n",
    "\n",
    "\n",
    "Empezaremos por el mas sencillo, una representación binaria. \n",
    "\n",
    "Tendremos que elegir todo un conjunto de parámetros sobre como se preprocesa y genera el vocabulario del texto, algunos los dejaremos por defecto, pero serían parte de los hiperparámetros que tendremos que explorar para encontrar el mejor modelo. Podéis verlos en (https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer)\n",
    "\n",
    "Modificaremos los siguientes:\n",
    " - `max_features` el número de palabras en el vocabulario, por defecto se escogen las más frecuentes que podría no ser la mejor opción, se puede controlar el rango de frecuencias que se escoge con otros paámetros, probaremos varias opciones\n",
    " - `stop_words` que pondremos a `english`\n",
    "\n",
    "El vectorizador nos retorna una matriz esparsa cuando tiene sentido, esto permitirá reducir el coste en memoria, pero no todos los modelos pueden trabajar con esta representación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size = 1000\n",
    "\n",
    "cvec = CountVectorizer(stop_words='english', max_features=voc_size, binary=True)\n",
    "\n",
    "X_train_v = cvec.fit_transform(X_train)\n",
    "X_test_v = cvec.transform(X_test)\n",
    "X_train_v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos visualizar el vocabulario que tenemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "wordcloud = WordCloud(background_color='white').generate_from_frequencies(cvec.vocabulary_)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.imshow(wordcloud, interpolation='bilinear');\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización\n",
    "\n",
    "Claramente no podemos hacer un análisis exploratorio de las variables o una visualización detallada, asi que utilizaremos reducción de dimensionalidad para observar la relación entre los atributos y las clases.\n",
    "\n",
    "Comenzaremos con PCA aunque claramente los atributos no se distribuyen de manera gausiana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "tdata = pca.fit_transform(np.asarray(X_train_v.todense()))\n",
    "dfdata = pd.concat([pd.DataFrame(tdata[:,:2]),pd.DataFrame({'label':y_train})],axis=1)\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "sns.scatterplot(x=0, y=1, hue='label', data=dfdata, palette='tab10');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claramente tampoco podemos esperar que unos pocos componentes expliquen la variancia de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6));\n",
    "plt.plot(range(1,len(pca.explained_variance_ratio_ )+1),pca.explained_variance_ratio_ ,alpha=0.8,marker='.',label=\"Variancia Explicada\");\n",
    "y_label = plt.ylabel('Variancia explicada');\n",
    "x_label = plt.xlabel('Componentes');\n",
    "plt.plot(range(1,len(pca.explained_variance_ratio_ )+1),\n",
    "         np.cumsum(pca.explained_variance_ratio_),\n",
    "         c='red',marker='.',\n",
    "         label=\"Variancia explicada acumulativa\");\n",
    "plt.legend();\n",
    "plt.title('Porcentaje de variancia explicada por componente');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que hay cierta separabilidad entre las clases, también la proyección nos da una idea de las relaciones entre ellas.\n",
    "\n",
    "Podemos usar también t-SNE dado que trabaja directamente con distancias. Lo inicializaremos con PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(init='pca')\n",
    "tdata = tsne.fit_transform(np.asarray(X_train_v.todense()))\n",
    "dfdata = pd.concat([pd.DataFrame(tdata[:,:2]),pd.DataFrame({'label':y_train})],axis=1);\n",
    "fig = plt.figure(figsize=(8,8));\n",
    "sns.scatterplot(x=0, y=1, hue='label', data=dfdata, palette='tab10');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines\n",
    "\n",
    "La idea de una SVM es encontrar el separador óptimo entre las clases que corresponderá con el hiperplano que maximice el margen entre ellas. Vimos que esto se puede obtener resolviendo un problema de programación cuadrática.\n",
    "\n",
    "Si las clases no son linealemente separables (como probablemente pasa en nuestro caso) podemos poner un límite al error que comete el clasificador para encontrar el separador. También podemos utilizar diferentes kernels que aumentan la dimensionalidad del espacio para obtener más fácilmente el separador.\n",
    "\n",
    "En este caso probaremos la SVM lineal, la SVM con kernel polinómico y la SVM con kernel RBF. \n",
    "\n",
    "Desde el punto de vista de la interpretabilidad sería mejor la SVM lineal, pero interpretar los pesos en este problema puede ser complicado, veremos más adelante como se pueden obtener explicaciones de la clasificación de ejemplos en este caso.\n",
    "\n",
    "#### Kernel lineal\n",
    "\n",
    "Empezaremos con la SVM lineal.\n",
    "\n",
    "Antes de usarla lo usual es normalizar los datos para usar la SVM. En este caso no lo necesitamos ya que los datos son binarios, pero podría ayudar a la convergencia en otros casos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'C':10**np.linspace(-3,3,101)}\n",
    "\n",
    "lsvc = SVC(kernel='linear', max_iter=25000, random_state=0)\n",
    "lsvc_gs = BayesSearchCV(lsvc,param,n_iter=niter, cv=cv, n_jobs=-1, refit=True, random_state=0)\n",
    "lsvc_gs.fit(X_train_v, y_train_l);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html(pd.DataFrame(lsvc_gs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head().to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que la separabilidad no es perfecta con este número de atributos, los artículos de astrofísica parecen ser los que se clasficican mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_l, lsvc_gs.predict(X_test_v), target_names=cls))\n",
    "results_df = save_results(lsvc_gs, X_test_v, y_test_l, 'linear SVM binary', results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los artículos de física son los que tienen más confusión con el resto, los de astrofísica no se parecen tanto a los de CS o de matematicas y entre estos dos también hay cierto solapamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "ConfusionMatrixDisplay.from_estimator(lsvc_gs, X_test_v, y_test_l, display_labels=cls, ax=plt.subplot());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la curva ROC también podemos ver que los articulos de astrofísica son los que se distinguen mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "roc_auc(lsvc_gs, X_train_v, y_train_l, X_test_v, y_test_l, classes=cls);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernels polinómicos\n",
    "\n",
    "Ahora probaremos usando kernels no lineales empezando por kernels polinómicos cuadráticos y cúbicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'C':10**np.linspace(-3,3,101), 'degree':[2,3]}\n",
    "\n",
    "psvc =  SVC(kernel='poly', max_iter=25000, random_state=0)\n",
    "psvc_gs = BayesSearchCV(psvc,param,n_iter=niter, cv=cv, n_jobs=-1, refit=True, random_state=0)\n",
    "psvc_gs.fit(X_train_v, y_train_l);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependiendo de la exploración podemos llegar a un resultado marginalmente mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html(pd.DataFrame(psvc_gs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head().to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos un resultado ligeramente mejor en el test, hemos perdido algo en los artículos de astrofísica, pero hemos ganado algo en el resto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_l, psvc_gs.predict(X_test_v), target_names=cls))\n",
    "results_df = save_results(psvc_gs, X_test_v, y_test_l, 'polynomial SVM binary', results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver un patron de confusión similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "ConfusionMatrixDisplay.from_estimator(psvc_gs, X_test_v, y_test_l, display_labels=cls, ax=plt.subplot());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La curva ROC parece bastante similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "roc_auc(psvc_gs, X_train_v, y_train_l, X_test_v, y_test_l, classes=cls);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel RBF\n",
    "\n",
    "Probamos ahora con el kernel gausiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'C':10**np.linspace(-3,3,101), 'gamma':['scale','auto']}\n",
    "\n",
    "rbsvc =  SVC(kernel='rbf', max_iter=25000, random_state=0)\n",
    "rbsvc_gs = BayesSearchCV(rbsvc,param,n_iter=niter, cv=cv, n_jobs=-1, refit=True, random_state=0)\n",
    "rbsvc_gs.fit(X_train_v, y_train_l);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependiendo de la exploración vemos otra ligera mejora en el resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html(pd.DataFrame(rbsvc_gs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head().to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el test se equilibran algo mas los resultados entre las clases con más confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_l, rbsvc_gs.predict(X_test_v), target_names=cls))\n",
    "results_df = save_results(rbsvc_gs, X_test_v, y_test_l, 'RBF SVM binary', results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probablemente hay artículos que combinan más de un tema y eso hace difícil distinguirlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "ConfusionMatrixDisplay.from_estimator(rbsvc_gs, X_test_v, y_test_l, display_labels=cls, ax=plt.subplot());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La curva ROC es ligeramente mejor para alguna clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "roc_auc(rbsvc_gs, X_train_v, y_train_l, X_test_v, y_test_l, classes=cls);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF como atributos\n",
    "\n",
    "Ahora podemos usar la frecuencia de las palabras en los documentos (TF) y su fecuencia en el corpus (IDF) como atributos. Eso hará que no solo usemos las palabras que aparecen en los textos, sino que también tengamos en cuenta su importancia en el documento y en el corpus de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvect = TfidfVectorizer(stop_words='english', max_features=voc_size)\n",
    "\n",
    "X_train_vt = cvect.fit_transform(X_train)\n",
    "X_test_vt = cvect.transform(X_test)\n",
    "X_train_vt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos visualizar el vocabulario que tenemos, hay ligeras diferencias dado que estamos dando ahora pesos a las palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "wordcloud = WordCloud(background_color='white').generate_from_frequencies(cvect.vocabulary_)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.imshow(wordcloud, interpolation='bilinear');\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización\n",
    "\n",
    "La proyección de PCA ha cambiado ligeramente, la relación espacial entre clase se ha mantenido, pero los ejemplos se han dispersado algo más con menor variancia en algunas direcciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "tdata = pca.fit_transform(np.asarray(X_train_vt.todense()))\n",
    "dfdata = pd.concat([pd.DataFrame(tdata[:,:2]),pd.DataFrame({'label':y_train})],axis=1)\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "sns.scatterplot(x=0, y=1, hue='label', data=dfdata, palette='tab10');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Podemos usar también t-SNE inicializado con PCA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(init='pca')\n",
    "tdata = tsne.fit_transform(np.asarray(X_train_vt.todense()))\n",
    "dfdata = pd.concat([pd.DataFrame(tdata[:,:2]),pd.DataFrame({'label':y_train})],axis=1)\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "sns.scatterplot(x=0, y=1, hue='label', data=dfdata, palette='tab10');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las mismas relaciones, quizás algo más de separabilidad que antes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines - TFIDF\n",
    "\n",
    "#### SVM lineal\n",
    "\n",
    "Vamos a aplicar las diferentes SVMs a esta nueva representación empezando con la SVM lineal.\n",
    "\n",
    "En este caso no tenemos datos binarios ahora si podemos normalizarlos, habitualmente eso ayuda a la convergencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmscaler = MinMaxScaler()\n",
    "\n",
    "X_train_vt_m = mmscaler.fit_transform(np.asarray(X_train_vt.todense()))\n",
    "X_test_vt_m = mmscaler.transform(np.asarray(X_test_vt.todense()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'C':10**np.linspace(-3,3,101)}\n",
    "\n",
    "lsvc =  SVC(kernel='linear', max_iter=25000, random_state=0)\n",
    "lsvc_gs = BayesSearchCV(lsvc,param,n_iter=niter, cv=cv, n_jobs=-1, refit=True, random_state=0)\n",
    "lsvc_gs.fit(X_train_vt_m, y_train_l);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html(pd.DataFrame(lsvc_gs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head().to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No hay una gran diferencia con la otra represesentación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_l, lsvc_gs.predict(X_test_vt_m), target_names=cls))\n",
    "results_df = save_results(lsvc_gs, X_test_vt_m, y_test_l, 'linear SVM TFIDF', results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "ConfusionMatrixDisplay.from_estimator(lsvc_gs, X_test_vt_m, y_test_l, display_labels=cls, ax=plt.subplot());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La confusión entre clases sigue siendo parecida y la curva ROC parece algo más suave en la clase más difícil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "roc_auc(lsvc_gs, X_train_vt_m, y_train_l, X_test_vt_m, y_test_l, classes=cls);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel Polinómico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'C':10**np.linspace(-3,3,101), 'degree':[2,3]}\n",
    "\n",
    "psvc =  SVC(kernel='poly', max_iter=25000, random_state=0)\n",
    "psvc_gs = BayesSearchCV(psvc,param,n_iter=niter, cv=cv, n_jobs=-1, refit=True, random_state=0)\n",
    "psvc_gs.fit(X_train_vt_m, y_train_l);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html(pd.DataFrame(psvc_gs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head().to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados son algo peores, per no hay gran diferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_l, psvc_gs.predict(X_test_vt_m), target_names=cls))\n",
    "results_df = save_results(psvc_gs, X_test_vt_m, y_test_l, 'polynomial SVM TFIDF', results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "ConfusionMatrixDisplay.from_estimator(psvc_gs, X_test_vt_m, y_test_l, display_labels=cls, ax=plt.subplot());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que la curva ROC de la clase más difícil se ha acercado a la de las clases CS y math, se ha equilibrado más la relacón entre precisión y recuperación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "roc_auc(psvc_gs, X_train_vt_m, y_train_l, X_test_vt_m, y_test_l, classes=cls);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'C':10**np.linspace(-3,3,101), 'gamma':['scale','auto']}\n",
    "\n",
    "rbsvc =  SVC(kernel='rbf', max_iter=25000, random_state=0)\n",
    "rbsvc_gs = BayesSearchCV(rbsvc,param,n_iter=niter, cv=cv, n_jobs=-1, refit=True, random_state=0)\n",
    "rbsvc_gs.fit(X_train_vt_m, y_train_l);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html(pd.DataFrame(rbsvc_gs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head().to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos resultados también parecidos a los de antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_l, rbsvc_gs.predict(X_test_vt_m), target_names=cls))\n",
    "results_df = save_results(rbsvc_gs, X_test_vt_m, y_test_l, 'RBF SVM TFIDF', results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "ConfusionMatrixDisplay.from_estimator(rbsvc_gs, X_test_vt_m, y_test_l, display_labels=cls, ax=plt.subplot());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "roc_auc(rbsvc_gs, X_train_vt_m, y_train_l, X_test_vt_m, y_test_l, classes=cls);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos son los resultados finales podemos ver que el acierto en la validación cruzada y en el test son muy parecidos, ninguno de los modelos se ha sobre especializado. \n",
    "\n",
    "Si elegimos el mejor modelos según el acierto en el conjunto de test entonces \n",
    "nos decidiriamos por la SVM con kernel RBF que da un resultado ligeramente mejor. Podemos ver que también es mejor en el resto de medidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.sort_values(by=['test acc'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección 2: Energy Data - Regresión\n",
    "\n",
    "Como vimos en la última sesión de laboratorio, un problema que se puede resolver mediante regresión es la predicción de series de tiempo.\n",
    "\n",
    "En este tipo de problemas queremos predecir valores de un momento en el tiempo a partir de los valores anteriores. En este caso debemos decidir cuantos instantes anteriores utilizamos y si utilizamos solo la variable objetivo o añadimos también otras variables que tengamos disponibles.\n",
    "\n",
    "Si recordais, en este problema queremos predecir el consumo de energia de los electrodomesticos de una casa. Tenemos muchos otros atributos, pero en este caso solo utilizaremos la variable objetivo. Podéis encontrar la documentación de este conjunto de datos aqui (https://archive.ics.uci.edu/ml/datasets/Appliances+energy+prediction)\n",
    "\n",
    "Podemos usar la SVM para regresión para realizar la misma tarea que en el notebook de Knn y MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "pd.set_option('display.precision', 5)\n",
    "\n",
    "niter = 15\n",
    "cv = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_energy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = data.loc[:,'Appliances']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos el mismo preproceso para poder comparar los resultados, de todas formas diferentes preprocesos pueden tener un impacto en la calidad del resultado. Una posibilidad es usar la serie a predecir sin preprocesar, es algo que podeis hacer vosotros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_train, e_test =  energy.iloc[:12000], energy.iloc[12000:]\n",
    "\n",
    "w = 4\n",
    "\n",
    "sdscaler = MinMaxScaler()\n",
    "\n",
    "e_train_s = sdscaler.fit_transform(e_train.to_numpy().reshape(-1, 1))\n",
    "e_test_s = sdscaler.transform(e_test.to_numpy().reshape(-1, 1))\n",
    "\n",
    "windows_train = sliding_window_view(e_train_s, w+1, axis=0).copy()\n",
    "X_train_w, y_train_w = windows_train.squeeze()[:,:-1], windows_train.squeeze()[:,-1]\n",
    "\n",
    "windows_test = sliding_window_view(e_test_s, w+1, axis=0).copy()\n",
    "X_test_w, y_test_w = windows_test.squeeze()[:,:-1], windows_test.squeeze()[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel lineal\n",
    "\n",
    "La SVM para regresión utiliza la epsilon insensitive loss. El valor del parámetro `epsilon` depende de la escala de los datos, en este caso [0,1], dependiendo del valor que le demos en este caso es posible que eso nos de un valor mínimo que pueda generar la regresión, asi que hemos de tener cuidado al usarlo y ver el efecto que tiene en la predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'C':10**np.linspace(-3,3,101), 'epsilon':np.linspace(0,0.01,11)}\n",
    "\n",
    "lsvr =  SVR(kernel='linear', max_iter=25000, cache_size=2000)\n",
    "lsvr_gs = BayesSearchCV(lsvr,param,n_iter=niter, \n",
    "                        cv=TimeSeriesSplit(n_splits=cv, gap=w+1), \n",
    "                        scoring=make_scorer(mean_squared_error, greater_is_better=False),\n",
    "                        n_jobs=-1, \n",
    "                        refit=True, random_state=0)\n",
    "lsvr_gs.fit(X_train_w, y_train_w);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html(pd.DataFrame(lsvr_gs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head().to_html())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que tenemos una predicción parecida a la de los otros dos modelos, ligeramente peor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test_w,lsvr_gs.predict(X_test_w)), mean_absolute_error(y_test_w,lsvr_gs.predict(X_test_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,10))\n",
    "plt.plot(y_test_w[:500],'r');\n",
    "plt.plot(lsvr_gs.predict(X_test_w[:500,:]),'b');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver también que la predicción en el conjunto de test también va siguiendo los valores reales.\n",
    "\n",
    "En los valores más bajos de la serie podemos ver que muchas veces la predicción es casi constante, eso puede tener que ver con el valor de `epsilon` que estamos usando. Eso no quiere decir que sea un problema, los valores mas bajos podrían ser básicamente ruido así que una predicción más suave podría ser más plausible, pero depende de la aplicación.\n",
    "\n",
    "### Kernel RBF\n",
    "\n",
    "Probamos ahora con el kernel RBF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'C':10**np.linspace(-3,3,101), 'gamma':['scale','auto'], 'epsilon':np.linspace(0,0.01,11)}\n",
    "\n",
    "rbsvr =  SVR(kernel='rbf', max_iter=50000, cache_size=2000)\n",
    "rbsvr_gs = BayesSearchCV(rbsvr,param,n_iter=niter, \n",
    "                        cv=TimeSeriesSplit(n_splits=cv, gap=w+1), \n",
    "                        scoring=make_scorer(mean_squared_error, greater_is_better=False),\n",
    "                        n_jobs=-1, \n",
    "                        refit=True, random_state=0)\n",
    "rbsvr_gs.fit(X_train_w, y_train_w);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html(pd.DataFrame(rbsvr_gs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head().to_html())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado es ligeramente mejor, más cerca al de los otros dos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test_w,rbsvr_gs.predict(X_test_w)), mean_absolute_error(y_test_w,rbsvr_gs.predict(X_test_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,10))\n",
    "plt.plot(y_test_w[:500],'r');\n",
    "plt.plot(rbsvr_gs.predict(X_test_w[:500,:]),'b');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También sigue bastante bien los datos de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Total Running time {timedelta(seconds=(time() - init_time))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
